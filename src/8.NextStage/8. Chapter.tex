\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{Next Stage}

Если уж мы рассматриваем задачу RL как попытку создания алгоритма <<искусственного интеллекта>>, то мы должны дополнительно учесть следующие три факта:
\begin{itemize}
    \item понятно, что в одной и той же среде агент может ставить себе совершенно разные задачи; интеллектуальное обучение должно позволять обобщать решения одних задач на другие, решать сложные задачи, состоящие из составных частей, и, наконец, уметь ставить себе <<промежуточные>> задачи самому.
    \item в общем случае, текущее наблюдение среды не описывает её состояние полностью, и агент, во-первых, должен обладать модулем памяти для запоминания предыдущих наблюдений, во-вторых, действовать в условиях неопределённости.
    \item наконец, в среде могут присутствовать другие агенты, которые могут иметь как схожие, так и противоположные цели, передавать вспомогательную информацию или, в частности, играть роль эксперта, демонстрирующих оптимальное (или полезное) поведение.
\end{itemize}
В этой главе мы обсудим ряд избранных идей в направлении этих соображений, которые не вписались в предыдущее повествование. 

\import{8.NextStage/}{8.1.ImitationLearning.tex}
\import{8.NextStage/}{8.2.IntrinsicMotivation.tex}
\import{8.NextStage/}{8.3.Multitask.tex}
\import{8.NextStage/}{8.4.Hierarchical.tex}
\import{8.NextStage/}{8.5.POMDP.tex}
\import{8.NextStage/}{8.6.MultiAgent.tex}

\end{document}